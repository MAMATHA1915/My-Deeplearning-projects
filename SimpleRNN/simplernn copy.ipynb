{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,SimpleRNN,Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 1000 #vocab size initialization\n",
    "(X_train,y_train),(X_test,y_test) = imdb.load_data(num_words = max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Train (25000,), y train (25000,) \n",
      "X Test (25000,), y test (25000,) \n"
     ]
    }
   ],
   "source": [
    "print(f'X Train {X_train.shape}, y train {y_train.shape} ')\n",
    "print(f'X Test {X_test.shape}, y test {y_test.shape} ')\n",
    "\n",
    "#sample \n",
    "sample_review = X_train[0]\n",
    "sample_label = y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 2, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(sample_review)\n",
    "print(sample_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping of words index to back to words\n",
    "word_index=imdb.get_word_index()\n",
    "#word_index\n",
    "reverse_word_index = {value: key for key, value in word_index.items()}\n",
    "reverse_word_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"? this film was just brilliant casting ? ? story direction ? really ? the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same ? ? as myself so i loved the fact there was a real ? with this film the ? ? throughout the film were great it was just brilliant so much that i ? the film as soon as it was released for ? and would recommend it to everyone to watch and the ? ? was amazing really ? at the end it was so sad and you know what they say if you ? at a film it must have been good and this definitely was also ? to the two little ? that played the ? of ? and paul they were just brilliant children are often left out of the ? ? i think because the stars that play them all ? up are such a big ? for the whole film but these children are amazing and should be ? for what they have done don't you think the whole story was so ? because it was true and was ? life after all that was ? with us all\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_review = \" \".join(reverse_word_index.get(i - 3 ,'?') for i in sample_review) \n",
    "decoded_review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "why using i-3?\n",
    "This is because the dataset (IMDB dataset from TensorFlow/Keras) reserves the first three indices for special tokens:\n",
    "\n",
    "Index\tToken\tMeaning\n",
    "\n",
    "0\t<pad>\tPadding token\n",
    "\n",
    "1\t<start>\tStart of a review\n",
    "\n",
    "2\t<unk>\tUnknown word (out-of-vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 500\n",
    "X_train = sequence.pad_sequences(X_train,maxlen = max_len)\n",
    "X_test = sequence.pad_sequences(X_test,maxlen= max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   1,  14,  22,  16,\n",
       "        43, 530, 973,   2,   2,  65, 458,   2,  66,   2,   4, 173,  36,\n",
       "       256,   5,  25, 100,  43, 838, 112,  50, 670,   2,   9,  35, 480,\n",
       "       284,   5, 150,   4, 172, 112, 167,   2, 336, 385,  39,   4, 172,\n",
       "         2,   2,  17, 546,  38,  13, 447,   4, 192,  50,  16,   6, 147,\n",
       "         2,  19,  14,  22,   4,   2,   2, 469,   4,  22,  71,  87,  12,\n",
       "        16,  43, 530,  38,  76,  15,  13,   2,   4,  22,  17, 515,  17,\n",
       "        12,  16, 626,  18,   2,   5,  62, 386,  12,   8, 316,   8, 106,\n",
       "         5,   4,   2,   2,  16, 480,  66,   2,  33,   4, 130,  12,  16,\n",
       "        38, 619,   5,  25, 124,  51,  36, 135,  48,  25,   2,  33,   6,\n",
       "        22,  12, 215,  28,  77,  52,   5,  14, 407,  16,  82,   2,   8,\n",
       "         4, 107, 117,   2,  15, 256,   4,   2,   7,   2,   5, 723,  36,\n",
       "        71,  43, 530, 476,  26, 400, 317,  46,   7,   4,   2,   2,  13,\n",
       "       104,  88,   4, 381,  15, 297,  98,  32,   2,  56,  26, 141,   6,\n",
       "       194,   2,  18,   4, 226,  22,  21, 134, 476,  26, 480,   5, 144,\n",
       "        30,   2,  18,  51,  36,  28, 224,  92,  25, 104,   4, 226,  65,\n",
       "        16,  38,   2,  88,  12,  16, 283,   5,  16,   2, 113, 103,  32,\n",
       "        15,  16,   2,  19, 178,  32], dtype=int32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train RNN\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features,128,input_length = max_len))\n",
    "model.add(SimpleRNN(128,activation='relu'))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 500, 128)          128000    \n",
      "                                                                 \n",
      " simple_rnn_4 (SimpleRNN)    (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 161025 (629.00 KB)\n",
      "Trainable params: 161025 (629.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy' ,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.EarlyStopping at 0x1483d93d0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stoppping =EarlyStopping(monitor = 'val_loss',patience = 5, restore_best_weights = True)\n",
    "early_stoppping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 60s 93ms/step - loss: 106692435968.0000 - accuracy: 0.6320 - val_loss: 0.6086 - val_accuracy: 0.6486\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 62s 99ms/step - loss: 0.5879 - accuracy: 0.6765 - val_loss: 0.5975 - val_accuracy: 0.6644\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 58s 92ms/step - loss: 0.5786 - accuracy: 0.6823 - val_loss: 0.5935 - val_accuracy: 0.6642\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 61s 97ms/step - loss: 0.5725 - accuracy: 0.6881 - val_loss: 0.5909 - val_accuracy: 0.6656\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 61s 98ms/step - loss: 0.5728 - accuracy: 0.6995 - val_loss: 0.5795 - val_accuracy: 0.6774\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 62s 98ms/step - loss: 0.6294 - accuracy: 0.7032 - val_loss: 0.5833 - val_accuracy: 0.6724\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 58s 93ms/step - loss: 0.5611 - accuracy: 0.7085 - val_loss: 0.5807 - val_accuracy: 0.6748\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 55s 88ms/step - loss: 0.5436 - accuracy: 0.7150 - val_loss: 0.5767 - val_accuracy: 0.6798\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 54s 87ms/step - loss: 0.6015 - accuracy: 0.7182 - val_loss: 0.5837 - val_accuracy: 0.6776\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 57s 92ms/step - loss: 0.5409 - accuracy: 0.7143 - val_loss: 0.5818 - val_accuracy: 0.6748\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,y_train,epochs=10,batch_size = 32,\n",
    "    validation_split =0.2,callbacks = [early_stoppping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mamatha/Desktop/mk files/files/venv/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('simple_rnn_imdb.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
